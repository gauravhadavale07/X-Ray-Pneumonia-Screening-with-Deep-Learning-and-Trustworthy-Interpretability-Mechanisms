{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> DenseNet-121 Training ‚Äî Interpretability-Focused Pipeline</h1>\n",
        "\n",
        "<p>\n",
        "This training block fine-tunes a <strong>DenseNet-121 model</strong> on the cleaned chest X-ray dataset while preserving visual interpretability of attention maps.\n",
        "Unlike performance-only pipelines, this setup avoids heavy or unrealistic augmentations and <strong>trains the model in a way that produces trustworthy Grad-CAM / Grad-CAM++ maps</strong>.\n",
        "</p>\n",
        "\n",
        "<h3>‚úî Key Training Decisions</h3>\n",
        "<ul>\n",
        "  <li>Grayscale to 3-channel replication (stable for medical models)</li>\n",
        "  <li>Only <strong>safe augmentations</strong> (no mixup, cutout, blur, noise)</li>\n",
        "  <li><strong>Full model fine-tuning</strong> for best saliency/attribution quality</li>\n",
        "  <li>Binary objective: Pneumonia vs Normal (<code>BCEWithLogitsLoss</code>)</li>\n",
        "  <li><strong>Best checkpoint saved using validation AUC</strong></li>\n",
        "</ul>\n",
        "\n",
        "<h3>Validation Metrics Used</h3>\n",
        "<ul>\n",
        "  <li>AUROC (primary)</li>\n",
        "  <li>F1-Score</li>\n",
        "</ul>\n",
        "\n",
        "<h3>Final Workflow Summary</h3>\n",
        "<ol>\n",
        "  <li>Load cleaned dataset (no ‚ÄúR‚Äù marker)</li>\n",
        "  <li>Split into Train / Validation / Test</li>\n",
        "  <li>Train DenseNet-121 end-to-end with Adam</li>\n",
        "  <li>Save only the best model based on <strong>highest validation AUROC</strong></li>\n",
        "  <li>Evaluate on the test set using the saved checkpoint</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "vLnEIcl4ZxVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup (Imports + Device + Drive + Unzip)"
      ],
      "metadata": {
        "id": "4mKc3zPYXly4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4D8W-4-XklH"
      },
      "outputs": [],
      "source": [
        "import os, shutil, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/X_ray_images/trust.zip\" -d \"/content/\"\n",
        "\n",
        "orig_train = \"/content/chest_xray/train\"\n",
        "orig_test  = \"/content/chest_xray/test\"\n",
        "clean_root = \"/content/chest_xray_cleaned\"\n",
        "clean_train = f\"{clean_root}/train\"\n",
        "clean_test  = f\"{clean_root}/test\"\n",
        "\n",
        "os.makedirs(clean_train, exist_ok=True)\n",
        "os.makedirs(clean_test, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove ‚ÄúR‚Äù Marker + Clean Dataset"
      ],
      "metadata": {
        "id": "Ab1mFQj_XzOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_R(np_img):\n",
        "    if len(np_img.shape) == 3:\n",
        "        np_img = cv2.cvtColor(np_img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = np_img.copy()\n",
        "    _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    mask = np.zeros_like(gray)\n",
        "    for c in contours:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        area = cv2.contourArea(c)\n",
        "        if 15 < w < 120 and 15 < h < 120 and 50 < area < 6000:\n",
        "            cv2.drawContours(mask, [c], -1, 255, -1)\n",
        "    cleaned = cv2.inpaint(gray, mask, 5, cv2.INPAINT_TELEA)\n",
        "    return cleaned\n",
        "\n",
        "def preprocess_folder(src, dst):\n",
        "    for class_name in [\"NORMAL\", \"PNEUMONIA\"]:\n",
        "        src_dir = os.path.join(src, class_name)\n",
        "        dst_dir = os.path.join(dst, class_name)\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        for f in tqdm(os.listdir(src_dir), desc=f\"Cleaning {class_name}\"):\n",
        "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                in_path  = os.path.join(src_dir, f)\n",
        "                out_path = os.path.join(dst_dir, f)\n",
        "                img = Image.open(in_path).convert(\"L\")\n",
        "                cleaned = remove_R(np.array(img))\n",
        "                Image.fromarray(cleaned).save(out_path)\n",
        "\n",
        "print(\"\\n=== CLEANING TRAIN SET ===\")\n",
        "preprocess_folder(orig_train, clean_train)\n",
        "print(\"\\n=== CLEANING TEST SET ===\")\n",
        "preprocess_folder(orig_test, clean_test)\n",
        "print(\"\\nCleaning complete.\")\n"
      ],
      "metadata": {
        "id": "rBQ3kVyHXyfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train/Val Split from Cleaned Data"
      ],
      "metadata": {
        "id": "gupvzfhkX2mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_train = \"/content/chest_xray_cleaned/new_train\"\n",
        "new_val   = \"/content/chest_xray_cleaned/new_val\"\n",
        "\n",
        "os.makedirs(new_train, exist_ok=True)\n",
        "os.makedirs(new_val, exist_ok=True)\n",
        "os.makedirs(f\"{new_train}/NORMAL\", exist_ok=True)\n",
        "os.makedirs(f\"{new_train}/PNEUMONIA\", exist_ok=True)\n",
        "os.makedirs(f\"{new_val}/NORMAL\", exist_ok=True)\n",
        "os.makedirs(f\"{new_val}/PNEUMONIA\", exist_ok=True)\n",
        "\n",
        "normal_imgs = [os.path.join(clean_train, \"NORMAL\", f) for f in os.listdir(os.path.join(clean_train, \"NORMAL\"))]\n",
        "pneu_imgs   = [os.path.join(clean_train, \"PNEUMONIA\", f) for f in os.listdir(os.path.join(clean_train, \"PNEUMONIA\"))]\n",
        "\n",
        "train_norm, val_norm = train_test_split(normal_imgs, test_size=0.15, random_state=42)\n",
        "train_pneu, val_pneu = train_test_split(pneu_imgs, test_size=0.15, random_state=42)\n",
        "\n",
        "def copy_list(files, dest):\n",
        "    for f in files:\n",
        "        shutil.copy(f, dest)\n",
        "\n",
        "copy_list(train_norm, f\"{new_train}/NORMAL\")\n",
        "copy_list(val_norm,   f\"{new_val}/NORMAL\")\n",
        "copy_list(train_pneu, f\"{new_train}/PNEUMONIA\")\n",
        "copy_list(val_pneu,   f\"{new_val}/PNEUMONIA\")\n",
        "\n",
        "print(\"\\nTrain/Val split ready.\")\n"
      ],
      "metadata": {
        "id": "aLMJoo7nX6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transforms(Train/Test)"
      ],
      "metadata": {
        "id": "u-ArNLCWYroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "WcxpD3FeYa7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datasets+Loaders"
      ],
      "metadata": {
        "id": "K88MprWFYxMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.ImageFolder(new_train, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(new_val,   transform=test_tfms)\n",
        "test_ds  = datasets.ImageFolder(clean_test, transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "IUXUvWjtYcg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model + Optimizer"
      ],
      "metadata": {
        "id": "11EpEJcIY14w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
        "model = model.to(device)\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "kQnInrMRYeC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train + Validation Functions"
      ],
      "metadata": {
        "id": "_oF6Al0BY4Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in tqdm(train_loader):\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    probs, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            out = model(imgs)\n",
        "            p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "            probs.extend(p)\n",
        "            trues.extend(labels.numpy())\n",
        "    probs = np.array(probs)\n",
        "    trues = np.array(trues)\n",
        "    auc = roc_auc_score(trues, probs)\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "    f1 = f1_score(trues, preds)\n",
        "    return auc, f1\n"
      ],
      "metadata": {
        "id": "WTr2eOV9Ygjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop (Save Best)"
      ],
      "metadata": {
        "id": "-zRQ-O9uY8ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_auc = 0\n",
        "save_dir = \"/content/saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "best_path = f\"{save_dir}/best_interpretability_model.pth\"\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "print(\"\\nStarting Training (Interpretability Mode ON)...\\n\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
        "    train_loss = train_epoch()\n",
        "    val_auc, val_f1 = evaluate(val_loader)\n",
        "\n",
        "    print(f\"Train Loss : {train_loss:.4f}\")\n",
        "    print(f\"Val AUC    : {val_auc:.4f}\")\n",
        "    print(f\"Val F1     : {val_f1:.4f}\")\n",
        "\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(f\" New BEST model saved ‚Üí {best_path}\")\n",
        "\n",
        "print(\"\\nTraining Complete!\")\n",
        "print(\"Best AUC:\", best_auc)\n",
        "print(\"Saved Best Model:\", best_path)\n"
      ],
      "metadata": {
        "id": "HcAtZSjsYjGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Evaluation Summary"
      ],
      "metadata": {
        "id": "5ABbS5g4ZAC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "\n",
        "print(f\"Loading weights from: {best_path}\")\n",
        "checkpoint = torch.load(best_path, map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_probs = []\n",
        "\n",
        "print(\"Running inference on Test Set...\")\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        imgs = imgs.to(device)\n",
        "        out = model(imgs)\n",
        "        probs = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        y_probs.extend(probs)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "y_pred = (y_probs > 0.5).astype(int)\n",
        "\n",
        "auc = roc_auc_score(y_true, y_probs)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\" ü©∫ FINAL TEST RESULTS\")\n",
        "print(\"=\"*30)\n",
        "print(f\"AUROC       : {auc:.4f}\")\n",
        "print(f\"F1 Score    : {f1:.4f}\")\n",
        "print(f\"Accuracy    : {(tp+tn)/len(y_true):.4f}\")\n",
        "print(f\"Sensitivity : {sensitivity:.4f}\")\n",
        "print(f\"Specificity : {specificity:.4f}\")\n",
        "print(\"=\"*30)\n",
        "print(\"\\nDetailed Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n"
      ],
      "metadata": {
        "id": "op7MVKNRYllS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix & ROC Plot"
      ],
      "metadata": {
        "id": "YHU-BRmnZE7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[\"Normal\", \"Pneumonia\"],\n",
        "            yticklabels=[\"Normal\", \"Pneumonia\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xGwrVYqsYnmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute Optimal Threshold and reevaluate with new Threshold"
      ],
      "metadata": {
        "id": "QSKp_puMZYhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_thresh = thresholds[ix]\n",
        "\n",
        "print(f\"Checking {len(thresholds)} possible thresholds...\")\n",
        "print(f\"üöÄ Best Threshold Found: {best_thresh:.4f}\")\n"
      ],
      "metadata": {
        "id": "NEjk95VPZS2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_new = (y_probs > best_thresh).astype(int)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_new).ravel()\n",
        "new_acc = (tp + tn) / len(y_true)\n",
        "new_sens = tp / (tp + fn)\n",
        "new_spec = tn / (tn + fp)\n"
      ],
      "metadata": {
        "id": "naHkcshXZUQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\" ‚öñÔ∏è  BALANCED RESULTS\")\n",
        "print(\"=\"*30)\n",
        "print(f\"Old Accuracy : {0.8125:.4f} -> New Accuracy : {new_acc:.4f}\")\n",
        "print(f\"Sensitivity  : {0.9974:.4f} -> New Sens     : {new_sens:.4f}\")\n",
        "print(f\"Specificity  : {0.5043:.4f} -> New Spec     : {new_spec:.4f}\")\n",
        "print(\"=\"*30)\n"
      ],
      "metadata": {
        "id": "D2QhL4pRZVzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
