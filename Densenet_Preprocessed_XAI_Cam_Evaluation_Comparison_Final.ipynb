{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and Setup"
      ],
      "metadata": {
        "id": "39tyOwt6btUb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Occ7ZZZarVA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model loading"
      ],
      "metadata": {
        "id": "pALgTW8XfQSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
        "model.load_state_dict(torch.load(\"/content/saved_models/best_interpretability_model.pth\"))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"âœ” GradCAM++ using DenseNet121 loaded.\")\n"
      ],
      "metadata": {
        "id": "JHoxnekvbaRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detect Last Conv Layer"
      ],
      "metadata": {
        "id": "OdxdakVMfST0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_conv(model):\n",
        "    layer = None\n",
        "    for _, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            layer = module\n",
        "    return layer\n",
        "\n",
        "target_layer = find_last_conv(model)\n",
        "print(\"âœ” Target layer:\", target_layer)\n"
      ],
      "metadata": {
        "id": "8_oBDgTxbc0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grad-CAM++ Class"
      ],
      "metadata": {
        "id": "vix8AH8Nfgbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAMPlusPlus:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "        def forward_hook(_, __, out): self.activations = out.detach()\n",
        "        def backward_hook(_, grad_in, grad_out): self.gradients = grad_out[0].detach()\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def generate(self, x):\n",
        "        self.model.zero_grad()\n",
        "        out = self.model(x)\n",
        "        logit = out[:, 0]\n",
        "        logit.backward(retain_graph=True)\n",
        "        A = self.activations\n",
        "        dA = self.gradients\n",
        "        alpha = dA.pow(2) / (2 * dA.pow(2) + (A * dA.pow(3)).sum(dim=(2,3), keepdim=True) + 1e-9)\n",
        "        weights = (alpha * dA.relu()).sum(dim=(2,3), keepdim=True)\n",
        "        cam = (weights * A).sum(dim=1).squeeze()\n",
        "        cam = torch.relu(cam)\n",
        "        cam -= cam.min()\n",
        "        cam /= (cam.max() + 1e-9)\n",
        "        return cam.cpu().numpy()\n",
        "\n",
        "gradcampp = GradCAMPlusPlus(model, target_layer)\n",
        "print(\"âœ” GradCAM++ initialized.\")\n"
      ],
      "metadata": {
        "id": "SHo1z9XfbedU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overlay CAM on Image and show Gradcam++"
      ],
      "metadata": {
        "id": "tUQH2WDTfj0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_cam(img_path, cam):\n",
        "    orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    orig = cv2.resize(orig, (224, 224))\n",
        "    orig_rgb = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    heat = cv2.applyColorMap((cam * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    overlay = (0.45 * heat + 0.55 * orig_rgb).astype(\"uint8\")\n",
        "    return overlay[:, :, ::-1]\n"
      ],
      "metadata": {
        "id": "yrRBhwIrbgBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_gradcam(img_path):\n",
        "    pil = Image.open(img_path).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    cam = gradcampp.generate(x)\n",
        "    overlay = overlay_cam(img_path, cam)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(\"GradCAM++ â€” DenseNet121\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WIScdqb-bh4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select Images (3 Bacterial + 5 Viral)"
      ],
      "metadata": {
        "id": "VByQYbjCfwdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "\n",
        "clean_pneu = \"/content/chest_xray_cleaned/test/PNEUMONIA\"\n",
        "files = sorted(os.listdir(clean_pneu))\n",
        "print(\"Total cleaned pneumonia images:\", len(files))\n",
        "\n",
        "bacteria_imgs = random.sample([f for f in files if \"bacteria\" in f.lower()], 3)\n",
        "virus_imgs = random.sample([f for f in files if \"virus\" in f.lower()], 5)\n",
        "\n",
        "print(\"Selected BACTERIAL images:\")\n",
        "for b in bacteria_imgs: print(\" -\", b)\n",
        "\n",
        "print(\"\\nSelected VIRAL images:\")\n",
        "for v in virus_imgs: print(\" -\", v)\n"
      ],
      "metadata": {
        "id": "3uboFGvBbjrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRunning GradCAM++...\\n\")\n",
        "for img_name in bacteria_imgs + virus_imgs:\n",
        "    path = f\"/content/chest_xray_cleaned/test/PNEUMONIA/{img_name}\"\n",
        "    print(f\"\\nðŸ” Image: {img_name}\")\n",
        "    show_gradcam(path)\n"
      ],
      "metadata": {
        "id": "jH42lnuKgSEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quantitative Metrics: Drop / Increase"
      ],
      "metadata": {
        "id": "LCFQHrWsf1bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_drop_increase(samples):\n",
        "    drops, increases = [], []\n",
        "    model.eval()\n",
        "    for fp in tqdm(samples, desc=\"Calculating Drop/Increase\"):\n",
        "        t = get_image_tensor(fp)\n",
        "        base_p = get_prob_from_model(t)\n",
        "        cam = gradcampp.generate(t)\n",
        "        cam = normalize_cam(upsample_cam(cam, (IMG_SIZE, IMG_SIZE)))\n",
        "        thr = np.percentile(cam, 60)\n",
        "        mask = (cam >= thr).astype(np.float32)\n",
        "        mask_t = torch.tensor(mask, dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(0).repeat(1,3,1,1)\n",
        "        x_masked = t * mask_t\n",
        "        masked_p = get_prob_from_model(x_masked)\n",
        "        drop = max(0.0, (base_p - masked_p) / (base_p + 1e-9)) * 100.0\n",
        "        drops.append(drop)\n",
        "        increases.append(1.0 if masked_p > base_p else 0.0)\n",
        "    return np.mean(drops), np.mean(increases) * 100.0\n"
      ],
      "metadata": {
        "id": "XkVgOE3SblqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quantitative Metrics: Insertion / Deletion AUC"
      ],
      "metadata": {
        "id": "ck9-cj2Lf4dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import auc as calc_auc\n",
        "\n",
        "def compute_ins_del_auc(samples, steps=100):\n",
        "    ins_aucs, del_aucs = [], []\n",
        "    model.eval()\n",
        "    for fp in tqdm(samples, desc=\"Calculating Insertion/Deletion AUC\"):\n",
        "        t = get_image_tensor(fp)\n",
        "        cam = gradcampp.generate(t)\n",
        "        cam = normalize_cam(upsample_cam(cam, (IMG_SIZE, IMG_SIZE)))\n",
        "        ins_p = insertion_deletion(fp, cam, steps=steps, mode='insertion')\n",
        "        del_p = insertion_deletion(fp, cam, steps=steps, mode='deletion')\n",
        "        ins_aucs.append(calc_auc(np.linspace(0,1,len(ins_p)), ins_p))\n",
        "        del_aucs.append(calc_auc(np.linspace(0,1,len(del_p)), del_p))\n",
        "    return np.mean(ins_aucs), np.mean(del_aucs)\n"
      ],
      "metadata": {
        "id": "rA5m1-x9bnSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate (Bacterial + Viral + Normal)"
      ],
      "metadata": {
        "id": "lqaHNnDDf8fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_root = \"/content/chest_xray_cleaned/test/NORMAL\"\n",
        "all_normals = sorted([os.path.join(normal_root, f) for f in os.listdir(normal_root) if f.endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "normal_samples = all_normals[:3]\n",
        "\n",
        "samples_all = [\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person122_bacteria_584.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person157_bacteria_739.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person101_bacteria_485.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person43_virus_92.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person1627_virus_2819.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person22_virus_55.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person38_virus_84.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person1672_virus_2888.jpeg\",\n",
        "] + normal_samples\n",
        "\n",
        "print(f\"Prepared {len(samples_all)} images for evaluation.\")\n"
      ],
      "metadata": {
        "id": "kMaUtISpbo9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Quantitative Scores"
      ],
      "metadata": {
        "id": "6u630SnhgAXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRunning Quantitative Metrics...\")\n",
        "avg_drop, avg_increase = avg_drop_increase(samples_all)\n",
        "ins_auc, del_auc = compute_ins_del_auc(samples_all, steps=50)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" FINAL AGGREGATE RESULTS (Normal + Pneumonia)\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Images Evaluated : {len(samples_all)}\")\n",
        "print(f\"Avg Drop (%)     : {avg_drop:.2f}\")\n",
        "print(f\"Avg Increase (%) : {avg_increase:.2f}\")\n",
        "print(f\"Insertion AUC    : {ins_auc:.4f}\")\n",
        "print(f\"Deletion AUC     : {del_auc:.4f}\")\n",
        "print(\"=\"*40)\n"
      ],
      "metadata": {
        "id": "1qWqvxdlbqcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br> <br> <br> <br>\n",
        "\n",
        "\n",
        "#BUILDING RISE PIPELINE"
      ],
      "metadata": {
        "id": "2NL221A0cLsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
        "model.load_state_dict(torch.load(\"/content/saved_models/best_interpretability_model.pth\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ” Loaded DenseNet121 for RISE.\")\n"
      ],
      "metadata": {
        "id": "50hGkTOFcM3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utility Functions"
      ],
      "metadata": {
        "id": "Z4g4qSWzccCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denorm_img(t):\n",
        "    x = t.cpu().numpy().transpose(1,2,0)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std  = np.array([0.229, 0.224, 0.225])\n",
        "    x = x * std + mean\n",
        "    return np.clip(x, 0, 1)\n",
        "\n",
        "def norm_for_model(x_np):\n",
        "    mean = np.array([0.485, 0.456, 0.406])[None,None,:]\n",
        "    std  = np.array([0.229, 0.224, 0.225])[None,None,:]\n",
        "    x = (x_np - mean) / std\n",
        "    return torch.tensor(x.transpose(2,0,1)).float().to(device)\n",
        "\n",
        "def preprocess_np(path):\n",
        "    pil = Image.open(path).convert(\"L\")\n",
        "    t = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    x_np = denorm_img(t[0])\n",
        "    return x_np, t\n"
      ],
      "metadata": {
        "id": "pu2zIo6kcZWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final RISE Class"
      ],
      "metadata": {
        "id": "f1y8_cQBcfUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RISE:\n",
        "    def __init__(self, model, N=1200, s=16, p=0.5):\n",
        "        self.model = model\n",
        "        self.N, self.s, self.p = N, s, p\n",
        "        self.masks = self.generate_masks().astype(\"float32\")\n",
        "\n",
        "    def generate_masks(self):\n",
        "        base = (np.random.rand(self.N, self.s, self.s) < self.p).astype(\"float32\")\n",
        "        masks = np.zeros((self.N, 224, 224), dtype=np.float32)\n",
        "        for i in range(self.N):\n",
        "            m = cv2.resize(base[i], (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "            masks[i] = cv2.GaussianBlur(m, (11,11), 0)\n",
        "        return masks\n",
        "\n",
        "    def explain(self, x_np):\n",
        "        masks = self.masks\n",
        "        imgs = [x_np * masks[i][...,None] for i in range(self.N)]\n",
        "        imgs = torch.stack([norm_for_model(im) for im in imgs], dim=0)\n",
        "\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.N, 64):\n",
        "                p = torch.sigmoid(self.model(imgs[i:i+64])).cpu().numpy().flatten()\n",
        "                probs.extend(p)\n",
        "\n",
        "        sal = np.tensordot(np.array(probs), masks, axes=(0,0))\n",
        "        sal -= sal.min()\n",
        "        sal /= sal.max() + 1e-8\n",
        "        sal = cv2.GaussianBlur(sal, (21,21), 0)\n",
        "        return sal\n",
        "\n",
        "rise = RISE(model, N=1200, s=16, p=0.5)\n",
        "print(\"âœ” RISE ready.\")\n"
      ],
      "metadata": {
        "id": "od9SND6HcevE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adaptive Heatmap Overlay"
      ],
      "metadata": {
        "id": "kbuN73CYclOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_rise_clean(img_path, sal, percentile=75):\n",
        "    orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if orig is None: return None\n",
        "    orig = cv2.resize(orig, (224,224))\n",
        "    orig_rgb = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    sal = cv2.GaussianBlur(cv2.resize(sal, (224,224)), (15,15), 0)\n",
        "    cutoff = np.percentile(sal, percentile)\n",
        "\n",
        "    mask = sal >= cutoff\n",
        "    sal_norm = np.maximum(sal - cutoff, 0)\n",
        "    sal_norm /= sal_norm.max() + 1e-9\n",
        "\n",
        "    heat = cv2.applyColorMap((sal_norm * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    final = orig_rgb.copy()\n",
        "    overlay = cv2.addWeighted(orig_rgb, 0.45, heat, 0.55, 0)\n",
        "    final[mask] = overlay[mask]\n",
        "\n",
        "    return final[:, :, ::-1]\n"
      ],
      "metadata": {
        "id": "B5Z7Cff8ckV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_rise_clean(img_path, label_text):\n",
        "    pil = Image.open(img_path).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        score = torch.sigmoid(model(x)).item()\n",
        "\n",
        "    x_np = x[0].permute(1,2,0).cpu().numpy()\n",
        "    sal = rise.explain(x_np)\n",
        "\n",
        "    overlay = overlay_rise_clean(img_path, sal, percentile=75)\n",
        "    if overlay is None: return\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f\"{label_text} â€” Conf: {score:.4f}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kWWFYS1hcprm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running on Selected Images"
      ],
      "metadata": {
        "id": "RmF6qCPkcw2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person122_bacteria_584.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person157_bacteria_739.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person101_bacteria_485.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person43_virus_92.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person1627_virus_2819.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person22_virus_55.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person38_virus_84.jpeg\",\n",
        "    \"/content/chest_xray_cleaned/test/PNEUMONIA/person1672_virus_2888.jpeg\"\n",
        "]\n",
        "\n",
        "print(f\"\\nProcessing {len(paths)} images...\\n\")\n",
        "for p in paths:\n",
        "    lbl = \"BACTERIA\" if \"bacteria\" in p else \"VIRUS\"\n",
        "    print(f\"â†’ {lbl}: {p.split('/')[-1]}\")\n",
        "    show_rise_clean(p, lbl)\n"
      ],
      "metadata": {
        "id": "3V1HrncVctk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br><br>"
      ],
      "metadata": {
        "id": "de-iazE6d6-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FULL XAI PIPELINE â€” SETUP + MODEL + 3 METHODS\n",
        "import os, cv2, torch, random, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---- Transforms (same as evaluation stage) ----\n",
        "IMG_SIZE = 224\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# ---- Load trained DenseNet121 (Interpretability Model) ----\n",
        "model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
        "model.load_state_dict(torch.load(\"/content/saved_models/best_interpretability_model.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ” DenseNet121 loaded for XAI\")\n",
        "\n",
        "\n",
        "#  GRADCAM++ (FINAL VERSION)\n",
        "\n",
        "class GradCAMPP:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        target_layer.register_forward_hook(self.save_activation)\n",
        "        target_layer.register_full_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        logit = self.model(x)\n",
        "        score = logit[:, 0]\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=True)\n",
        "\n",
        "        gradients = self.gradients\n",
        "        activations = self.activations\n",
        "        b, k, u, v = gradients.size()\n",
        "\n",
        "        alpha_num = gradients.pow(2)\n",
        "        alpha_denom = 2 * gradients.pow(2) + torch.sum(activations * gradients.pow(3), axis=(2, 3)).view(b, k, 1, 1)\n",
        "        alpha_denom = torch.where(alpha_denom != 0.0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "        alphas = alpha_num / alpha_denom\n",
        "\n",
        "        weights = torch.maximum(score.exp() * gradients, torch.tensor(0.0).to(gradients.device))\n",
        "        weights = torch.sum(alphas * weights, axis=(2, 3)).view(b, k, 1, 1)\n",
        "\n",
        "        saliency_map = torch.sum(weights * activations, axis=1)\n",
        "        saliency_map = F.relu(saliency_map)\n",
        "        saliency_map = saliency_map.view(b, -1)\n",
        "        saliency_map -= saliency_map.min(1, keepdim=True)[0]\n",
        "        saliency_map /= saliency_map.max(1, keepdim=True)[0]\n",
        "        saliency_map = saliency_map.view(b, u, v)\n",
        "        return saliency_map.data\n",
        "\n",
        "target_layer = model.features.denseblock4.denselayer16.conv2\n",
        "gradcam_pp = GradCAMPP(model, target_layer)\n",
        "print(\"âœ” GradCAM++ initialized\")\n",
        "\\\n",
        "#  ABLATIONCAM\n",
        "\n",
        "def ablation_cam(x):\n",
        "    out = model.features(x)\n",
        "    B, C, H, W = out.shape\n",
        "    base = torch.sigmoid(model(x)).item()\n",
        "    cam = torch.zeros((H, W), device=x.device)\n",
        "\n",
        "    for c in range(C):\n",
        "        masked = out.clone()\n",
        "        masked[:, c] = 0\n",
        "        score = torch.sigmoid(model.classifier(masked.mean(dim=(2,3)))).item()\n",
        "        cam += (base - score)\n",
        "\n",
        "    cam -= cam.min()\n",
        "    cam /= (cam.max() + 1e-9)\n",
        "    return cam.detach().cpu().numpy()\n",
        "\n",
        "print(\"âœ” AblationCAM initialized\")\n",
        "\n",
        "#  RISE (HIGH-RES ADAPTIVE VERSION)\n",
        "\n",
        "def denorm_img(t):\n",
        "    x = t.cpu().numpy().transpose(1,2,0)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std  = np.array([0.229, 0.224, 0.225])\n",
        "    return np.clip(x * std + mean, 0, 1)\n",
        "\n",
        "def preprocess_np(path):\n",
        "    pil = Image.open(path).convert(\"L\")\n",
        "    t = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    return denorm_img(t[0]), t\n",
        "\n",
        "class RISE:\n",
        "    def __init__(self, model, N=1200, s=16, p=0.5):\n",
        "        self.model = model\n",
        "        self.N = N\n",
        "        self.s = s\n",
        "        self.p = p\n",
        "        self.masks = self.generate_masks()\n",
        "\n",
        "    def generate_masks(self):\n",
        "        base = (np.random.rand(self.N, self.s, self.s) < self.p).astype(\"float32\")\n",
        "        masks = np.zeros((self.N, 224, 224), dtype=np.float32)\n",
        "        for i in range(self.N):\n",
        "            m = cv2.resize(base[i], (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "            masks[i] = cv2.GaussianBlur(m, (11,11), 0)\n",
        "        return masks\n",
        "\n",
        "    def explain(self, x_np):\n",
        "        masks = self.masks\n",
        "        imgs = np.stack([x_np * m[...,None] for m in masks])\n",
        "        mean = torch.tensor([0.485,0.456,0.406], device=device)[None,:,None,None]\n",
        "        std  = torch.tensor([0.229,0.224,0.225], device=device)[None,:,None,None]\n",
        "        imgs = torch.tensor(imgs).permute(0,3,1,2).float().to(device)\n",
        "        imgs = (imgs - mean) / std\n",
        "\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.N, 64):\n",
        "                out = self.model(imgs[i:i+64])\n",
        "                probs.extend(torch.sigmoid(out).cpu().numpy().flatten())\n",
        "        sal = np.tensordot(np.array(probs), masks, axes=(0,0))\n",
        "        sal -= sal.min()\n",
        "        sal /= (sal.max() + 1e-8)\n",
        "        sal = cv2.GaussianBlur(sal, (21,21), 0)\n",
        "        return sal\n",
        "\n",
        "rise = RISE(model, N=1200, s=16, p=0.5)\n",
        "print(\"âœ” RISE initialized\")\n"
      ],
      "metadata": {
        "id": "s7U3hOZbd6Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM SAMPLING + OVERLAY + 3Ã—3 PANELS (3 METHODS)\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# RANDOM IMAGE SELECTION\n",
        "normal_dir = \"/content/chest_xray_cleaned/test/NORMAL\"\n",
        "pneu_dir   = \"/content/chest_xray_cleaned/test/PNEUMONIA\"\n",
        "\n",
        "all_normal   = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith(('.jpeg','.jpg','.png'))]\n",
        "all_pneu     = [os.path.join(pneu_dir, f) for f in os.listdir(pneu_dir) if f.endswith(('.jpeg','.jpg','.png'))]\n",
        "all_bacteria = [f for f in all_pneu if \"bacteria\" in f.lower()]\n",
        "all_virus    = [f for f in all_pneu if \"virus\" in f.lower()]\n",
        "\n",
        "sel_normal   = random.sample(all_normal, 3)\n",
        "sel_bacteria = random.sample(all_bacteria, 3)\n",
        "sel_virus    = random.sample(all_virus, 3)\n",
        "\n",
        "paths  = sel_normal + sel_bacteria + sel_virus\n",
        "labels = [\"Normal 1\",\"Normal 2\",\"Normal 3\",\n",
        "          \"Bacteria 1\",\"Bacteria 2\",\"Bacteria 3\",\n",
        "          \"Virus 1\",\"Virus 2\",\"Virus 3\"]\n",
        "\n",
        "print(f\"Selected {len(paths)} images (3 Normal, 3 Bacteria, 3 Virus)\")\n",
        "\n",
        "# ------------------------- OVERLAY FUNCTION -------------------------\n",
        "def create_overlay(img_path, heatmap, use_adaptive=False):\n",
        "    orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    orig = cv2.resize(orig, (224,224))\n",
        "    orig_rgb = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "    heatmap = cv2.resize(heatmap, (224,224))\n",
        "\n",
        "    if use_adaptive:\n",
        "        heatmap = cv2.GaussianBlur(heatmap, (15, 15), 0)\n",
        "        cutoff = np.percentile(heatmap, 75)\n",
        "        mask_indices = heatmap < cutoff\n",
        "\n",
        "        heatmap_norm = heatmap.copy()\n",
        "        heatmap_norm -= cutoff\n",
        "        heatmap_norm[heatmap_norm < 0] = 0\n",
        "        heatmap_norm /= (heatmap_norm.max() + 1e-9)\n",
        "\n",
        "        heat_color = cv2.applyColorMap((heatmap_norm * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "        overlay = cv2.addWeighted(orig_rgb, 0.5, heat_color, 0.5, 0)\n",
        "\n",
        "        final_img = orig_rgb.copy()\n",
        "        final_img[~mask_indices] = overlay[~mask_indices]\n",
        "        final_img[mask_indices]  = orig_rgb[mask_indices]\n",
        "        return final_img[:, :, ::-1]\n",
        "\n",
        "    heat_color = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    overlay = cv2.addWeighted(orig_rgb, 0.5, heat_color, 0.5, 0)\n",
        "    return overlay[:, :, ::-1]\n",
        "\n",
        "# ---------------------- GENERATE ALL 3 METHODS ----------------------\n",
        "rise_images      = []\n",
        "grad_images      = []\n",
        "ablation_images  = []\n",
        "\n",
        "print(\"Generating RISE + GradCAM++ + AblationCAM maps...\")\n",
        "\n",
        "for p in tqdm(paths):\n",
        "    pil = Image.open(p).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    x_np = x[0].permute(1,2,0).cpu().numpy()\n",
        "\n",
        "    rise_map = rise.explain(x_np)\n",
        "    rise_images.append(create_overlay(p, rise_map, use_adaptive=True))\n",
        "\n",
        "    grad_map = gradcam_pp(x).cpu().numpy()[0]\n",
        "    grad_images.append(create_overlay(p, grad_map, use_adaptive=False))\n",
        "\n",
        "    abl_map = ablation_cam(x)\n",
        "    ablation_images.append(create_overlay(p, abl_map, use_adaptive=False))\n",
        "\n",
        "# --------------------------- PANEL FUNCTION ---------------------------\n",
        "def plot_3x3_panel(image_list, title_main):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "    fig.suptitle(title_main, fontsize=20, weight=\"bold\", y=0.98)\n",
        "    row_titles = [\"NORMAL\", \"BACTERIA\", \"VIRUS\"]\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(image_list[i])\n",
        "        ax.set_title(labels[i], fontsize=10)\n",
        "        if i % 3 == 0:\n",
        "            ax.set_ylabel(row_titles[i//3], fontsize=14, weight=\"bold\")\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        for spine in ax.spines.values(): spine.set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------ SHOW PANELS ------------------------------\n",
        "print(\"\\n---------------- RISE PANEL ----------------\")\n",
        "plot_3x3_panel(rise_images, \"RISE (Adaptive Threshold â€” Top 25%)\")\n",
        "\n",
        "print(\"\\n---------------- GRADCAM++ PANEL ----------------\")\n",
        "plot_3x3_panel(grad_images, \"GradCAM++ (Gradient-Based)\")\n",
        "\n",
        "print(\"\\n---------------- ABLATIONCAM PANEL ----------------\")\n",
        "plot_3x3_panel(ablation_images, \"AblationCAM (Perturbation-Based)\")\n"
      ],
      "metadata": {
        "id": "zeqyp2g5d6i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  BLOCK 3 â€” Quantitative Metrics, Export, Panels, Error Analysis\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Running quantitative evaluation...\")\n",
        "\n",
        "# --------------------------- Helper: Clean saliency map ---------------------------\n",
        "def clean_map(saliency_map, percentile=75):\n",
        "    if saliency_map.shape != (224,224):\n",
        "        saliency_map = cv2.resize(saliency_map, (224, 224))\n",
        "    saliency_map = cv2.GaussianBlur(saliency_map, (15, 15), 0)\n",
        "    cutoff = np.percentile(saliency_map, percentile)\n",
        "    saliency_map[saliency_map < cutoff] = 0\n",
        "    saliency_map -= saliency_map.min()\n",
        "    saliency_map /= (saliency_map.max() + 1e-9)\n",
        "    return saliency_map\n",
        "\n",
        "# ---------------------- Metric 1: Sparsity / Complexity ----------------------\n",
        "metrics_clean = {\"RISE\":{\"sparsity\":[], \"entropy\":[]},\n",
        "                 \"GradCAM\":{\"sparsity\":[], \"entropy\":[]},\n",
        "                 \"Ablation\":{\"sparsity\":[], \"entropy\":[]}}\n",
        "\n",
        "print(\"Computing Sparsity and Entropy on CLEAN maps...\")\n",
        "for p in tqdm(paths):\n",
        "    pil = Image.open(p).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    x_np = x[0].permute(1,2,0).cpu().numpy()\n",
        "\n",
        "    rise_raw = rise.explain(x_np)\n",
        "    grad_raw = gradcam_pp(x).cpu().numpy()[0]\n",
        "    abl_raw  = ablation_cam(x)\n",
        "\n",
        "    rise_clean = clean_map(rise_raw)\n",
        "    grad_clean = clean_map(grad_raw)\n",
        "    abl_clean  = clean_map(abl_raw)\n",
        "\n",
        "    metrics_clean[\"RISE\"][\"sparsity\"].append(calculate_sparsity(rise_clean))\n",
        "    metrics_clean[\"RISE\"][\"entropy\"].append(calculate_complexity(rise_clean))\n",
        "\n",
        "    metrics_clean[\"GradCAM\"][\"sparsity\"].append(calculate_sparsity(grad_clean))\n",
        "    metrics_clean[\"GradCAM\"][\"entropy\"].append(calculate_complexity(grad_clean))\n",
        "\n",
        "    metrics_clean[\"Ablation\"][\"sparsity\"].append(calculate_sparsity(abl_clean))\n",
        "    metrics_clean[\"Ablation\"][\"entropy\"].append(calculate_complexity(abl_clean))\n",
        "\n",
        "# ---------------------- Metric 2: Faithfulness (RAW maps) ----------------------\n",
        "def calculate_faithfulness(model, img_tensor, saliency_map, num_masks=50):\n",
        "    model.eval()\n",
        "    if saliency_map.shape != (224,224):\n",
        "        saliency_map = cv2.resize(saliency_map, (224, 224))\n",
        "    with torch.no_grad():\n",
        "        base_pred = torch.sigmoid(model(img_tensor)).item()\n",
        "\n",
        "    flattened = saliency_map.flatten()\n",
        "    sorted_idx = np.argsort(flattened)[::-1]\n",
        "    total_pixels = len(flattened)\n",
        "    step = max(1, total_pixels // num_masks)\n",
        "\n",
        "    masked_img = img_tensor.clone()\n",
        "    intensities_removed = []\n",
        "    score_drops = []\n",
        "\n",
        "    for i in range(0, total_pixels, step):\n",
        "        idx = sorted_idx[i : i+step]\n",
        "        if len(idx) == 0:\n",
        "            break\n",
        "        intensities_removed.append(np.sum(flattened[idx]))\n",
        "        ys = idx // 224\n",
        "        xs = idx % 224\n",
        "        masked_img[0, :, ys, xs] = 0.0\n",
        "        with torch.no_grad():\n",
        "            new_pred = torch.sigmoid(model(masked_img)).item()\n",
        "        score_drops.append(base_pred - new_pred)\n",
        "\n",
        "    if np.std(score_drops) == 0 or np.std(intensities_removed) == 0:\n",
        "        return 0\n",
        "    return pearsonr(intensities_removed, score_drops)[0]\n",
        "\n",
        "faith_scores = {\"RISE\":[], \"GradCAM\":[], \"Ablation\":[]}\n",
        "\n",
        "print(\"Computing Faithfulness Correlation on RAW maps...\")\n",
        "for p in tqdm(paths):\n",
        "    pil = Image.open(p).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "    x_np = x[0].permute(1,2,0).cpu().numpy()\n",
        "\n",
        "    rise_raw = rise.explain(x_np)\n",
        "    grad_raw = gradcam_pp(x).cpu().numpy()[0]\n",
        "    abl_raw  = ablation_cam(x)\n",
        "\n",
        "    faith_scores[\"RISE\"].append(calculate_faithfulness(model, x, rise_raw))\n",
        "    faith_scores[\"GradCAM\"].append(calculate_faithfulness(model, x, grad_raw))\n",
        "    faith_scores[\"Ablation\"].append(calculate_faithfulness(model, x, abl_raw))\n",
        "\n",
        "# ---------------------- Building CSV tables ----------------------\n",
        "print(\"Saving metric tables...\")\n",
        "\n",
        "df_raw = pd.DataFrame({\n",
        "    \"Method\": [\"GradCAM++\", \"AblationCAM\", \"RISE\"],\n",
        "    \"Faithfulness_Correlation\": [\n",
        "        np.mean(faith_scores[\"GradCAM\"]),\n",
        "        np.mean(faith_scores[\"Ablation\"]),\n",
        "        np.mean(faith_scores[\"RISE\"]),\n",
        "    ]\n",
        "})\n",
        "df_raw.to_csv(\"/content/table_raw_metrics.csv\", index=False)\n",
        "\n",
        "df_clean = pd.DataFrame({\n",
        "    \"Method\": [\"GradCAM++\", \"AblationCAM\", \"RISE\"],\n",
        "    \"Sparsity_Gini_Clean\": [\n",
        "        np.mean(metrics_clean[\"GradCAM\"][\"sparsity\"]),\n",
        "        np.mean(metrics_clean[\"Ablation\"][\"sparsity\"]),\n",
        "        np.mean(metrics_clean[\"RISE\"][\"sparsity\"]),\n",
        "    ],\n",
        "    \"Entropy_Clean\": [\n",
        "        np.mean(metrics_clean[\"GradCAM\"][\"entropy\"]),\n",
        "        np.mean(metrics_clean[\"Ablation\"][\"entropy\"]),\n",
        "        np.mean(metrics_clean[\"RISE\"][\"entropy\"]),\n",
        "    ],\n",
        "})\n",
        "df_clean.to_csv(\"/content/table_clean_metrics.csv\", index=False)\n",
        "\n",
        "df_final = pd.DataFrame({\n",
        "    \"Method\": [\"GradCAM++\", \"AblationCAM\", \"RISE (Ours)\"],\n",
        "    \"Faithfulness (Raw)\": df_raw[\"Faithfulness_Correlation\"],\n",
        "    \"Sparsity (Clean)\": df_clean[\"Sparsity_Gini_Clean\"],\n",
        "    \"Complexity (Clean)\": df_clean[\"Entropy_Clean\"],\n",
        "})\n",
        "df_final.to_csv(\"/content/FINAL_PUBLICATION_TABLE.csv\", index=False)\n",
        "\n",
        "# ---------------------- Saving PNG panels----------------------\n",
        "def save_panel(img_list, title, filename):\n",
        "    fig, ax = plt.subplots(3, 3, figsize=(12,12))\n",
        "    fig.suptitle(title, fontsize=20, weight='bold')\n",
        "    row_titles = [\"NORMAL\",\"BACTERIA\",\"VIRUS\"]\n",
        "    for i, axis in enumerate(ax.flat):\n",
        "        axis.imshow(img_list[i])\n",
        "        axis.set_title(labels[i], fontsize=10)\n",
        "        if i % 3 == 0:\n",
        "            axis.set_ylabel(row_titles[i//3], fontsize=14, weight='bold')\n",
        "        axis.set_xticks([]); axis.set_yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/{filename}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "save_panel(rise_images, \"RISE\", \"Figure_1_RISE\")\n",
        "save_panel(grad_images, \"GradCAM++\", \"Figure_2_GradCAM\")\n",
        "save_panel(ablation_images, \"AblationCAM\", \"Figure_3_Ablation\")\n",
        "\n",
        "# ---------------------- ZIP & DOWNLOAD ----------------------\n",
        "print(\"Creating ZIP...\")\n",
        "os.system(\"zip -r /content/Complete_Research_Results.zip /content/*.csv /content/*.png\")\n",
        "\n",
        "print(\"Starting download...\")\n",
        "files.download(\"/content/Complete_Research_Results.zip\")\n",
        "\n",
        "# ---------------------- Identifying high-confidence errors ----------------------\n",
        "print(\"Scanning for high-confidence mistakes...\")\n",
        "fp_paths, fn_paths = [], []\n",
        "\n",
        "for i, (img, label) in enumerate(test_ds):\n",
        "    img_tensor = img.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        score = torch.sigmoid(model(img_tensor)).item()\n",
        "\n",
        "    path = test_ds.samples[i][0]\n",
        "    if label == 0 and score > 0.90 and len(fp_paths) < 2:\n",
        "        fp_paths.append(path)\n",
        "    if label == 1 and score < 0.10 and len(fn_paths) < 2:\n",
        "        fn_paths.append(path)\n",
        "\n",
        "error_paths = fp_paths + fn_paths\n",
        "print(\"Errors detected:\", len(error_paths))\n",
        "\n",
        "for p in error_paths:\n",
        "    if \"NORMAL\" in p:\n",
        "        lbl = \"False Positive (Normal predicted as Pneumonia)\"\n",
        "    else:\n",
        "        lbl = \"False Negative (Pneumonia predicted as Normal)\"\n",
        "    show_rise_clean(p, lbl)\n",
        "\n",
        "print(\"Block 3 complete.\")\n"
      ],
      "metadata": {
        "id": "S7VrfMM0enYa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}