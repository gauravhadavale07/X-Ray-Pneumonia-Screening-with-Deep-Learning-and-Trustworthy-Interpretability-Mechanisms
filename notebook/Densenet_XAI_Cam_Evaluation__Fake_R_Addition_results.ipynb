{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Necessary Libraries and modules"
      ],
      "metadata": {
        "id": "rcT6ibRYSIJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdvrYt_bRxRp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GradCAM++ Class"
      ],
      "metadata": {
        "id": "KC3nWZJfSJSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAMPlusPlus:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.target_layer = target_layer\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        def forward_hook(module, inp, out):\n",
        "            self.activations = out.detach()\n",
        "\n",
        "        def backward_hook(module, grad_in, grad_out):\n",
        "            self.gradients = grad_out[0].detach()\n",
        "\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def generate(self, x):\n",
        "        self.model.zero_grad()\n",
        "        logits = self.model(x)\n",
        "        class_idx = logits.argmax(dim=1).item()\n",
        "        loss = logits[:, class_idx]\n",
        "        loss.backward()\n",
        "\n",
        "        grad = self.gradients\n",
        "        act = self.activations\n",
        "\n",
        "        numerator = grad.pow(2)\n",
        "        denominator = (2 * grad.pow(2)) + (act * grad.pow(3)).sum(dim=(2,3), keepdim=True)\n",
        "        denominator = torch.where(denominator != 0, denominator, torch.ones_like(denominator))\n",
        "        alpha = numerator / denominator\n",
        "\n",
        "        weights = (alpha * torch.relu(grad)).sum(dim=(2,3), keepdim=True)\n",
        "        cam = (weights * act).sum(dim=1).squeeze()\n",
        "\n",
        "        cam = torch.relu(cam)\n",
        "        cam -= cam.min()\n",
        "        cam /= (cam.max() + 1e-9)\n",
        "\n",
        "        return cam.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "XcMH10OFSCOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detect Last Conv Layer"
      ],
      "metadata": {
        "id": "Y-YXcY6QSZSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_conv_layer(model):\n",
        "    last = None\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            last = module\n",
        "    return last\n",
        "\n",
        "target_layer = find_last_conv_layer(model)\n",
        "campp = GradCAMPlusPlus(model, target_layer)\n",
        "print(\"Using target conv layer:\", target_layer)\n"
      ],
      "metadata": {
        "id": "qlb8yqGWSEZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display GradCAM++ Overlay on Image"
      ],
      "metadata": {
        "id": "NHW-jSuaSgaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_gradcam_pp(img_path):\n",
        "    orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    orig = cv2.resize(orig, (224, 224))\n",
        "    pil_img = Image.open(img_path).convert(\"L\")\n",
        "    x = test_tfms(pil_img).unsqueeze(0).to(device)\n",
        "\n",
        "    cam = campp.generate(x)\n",
        "    cam_resized = cv2.resize(cam, (224, 224))\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
        "    orig_rgb = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = (0.4 * heatmap + 0.6 * orig_rgb).astype(np.uint8)\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(overlay[:,:,::-1])\n",
        "    plt.title(\"GradCAM++ Overlay\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ly-0uPb7SG1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_tRFcjhWS54C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RISE Class Implementation"
      ],
      "metadata": {
        "id": "PXDjzpbrTA9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RISE:\n",
        "    def __init__(self, model, input_size=(224, 224), N=4000, s=7, p=0.5):\n",
        "        self.model = model.eval()\n",
        "        self.H, self.W = input_size\n",
        "        self.N = N\n",
        "        self.s = s\n",
        "        self.p = p\n",
        "        print(\"⚡ Generating random masks...\")\n",
        "        self.masks = self.generate_masks()\n",
        "\n",
        "    def generate_masks(self):\n",
        "        cell_h = self.H // self.s\n",
        "        cell_w = self.W // self.s\n",
        "        masks = []\n",
        "        for _ in tqdm(range(self.N)):\n",
        "            grid = np.random.choice([0, 1], size=(self.s, self.s), p=[1-self.p, self.p]).astype(np.float32)\n",
        "            mask = cv2.resize(grid, (self.W, self.H), interpolation=cv2.INTER_NEAREST)\n",
        "            masks.append(mask)\n",
        "        return np.stack(masks)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def explain(self, img_tensor):\n",
        "        saliency = np.zeros((self.H, self.W), dtype=np.float32)\n",
        "        for mask in tqdm(self.masks, desc=\"RISE\"):\n",
        "            masked_img = img_tensor * torch.tensor(mask).to(img_tensor.device)\n",
        "            output = self.model(masked_img)\n",
        "            prob = torch.sigmoid(output).item()\n",
        "            saliency += prob * mask\n",
        "        saliency /= self.N\n",
        "        saliency -= saliency.min()\n",
        "        saliency /= saliency.max() + 1e-9\n",
        "        return saliency\n"
      ],
      "metadata": {
        "id": "eRRSpOv-S86y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running & Visualizing RISE"
      ],
      "metadata": {
        "id": "2kgdyAQOTE_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_rise(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    pil = Image.open(img_path).convert(\"L\")\n",
        "    x = test_tfms(pil).unsqueeze(0).to(device)\n",
        "\n",
        "    rise = RISE(model, input_size=(224,224), N=2000, s=7, p=0.5)\n",
        "    sal = rise.explain(x)\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * sal), cv2.COLORMAP_JET)\n",
        "    orig_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = (0.5 * heatmap + 0.5 * orig_rgb).astype(np.uint8)\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(overlay[:,:,::-1])\n",
        "    plt.title(\"RISE Saliency Map\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "o1Q0hUvAS-Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "gRtSxu1_T8qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br><br><br><br><br>\n",
        "<br><br><br><br><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WF-pvVFCUtXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADDING FAKE 'R' ON OUR NORMAL IMAGES AND THEN TESTING OUR METRICS"
      ],
      "metadata": {
        "id": "7dfGE9A_VD7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding Artificial Marker function to add on normal images"
      ],
      "metadata": {
        "id": "LI0sjwBKUEQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prob(img_tensor):\n",
        "    with torch.no_grad():\n",
        "        out = model(img_tensor.to(device))\n",
        "        prob = torch.sigmoid(out).item()\n",
        "    return prob"
      ],
      "metadata": {
        "id": "OwHPZ9jeUDET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_R_marker(gray_224):\n",
        "    img = gray_224.copy()\n",
        "    cv2.putText(img, 'R', org=(5, 70), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                fontScale=1.8, color=(255,), thickness=3, lineType=cv2.LINE_AA)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "KO3RC1CvULjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_norm_dir = \"/content/chest_xray/test/NORMAL\"\n",
        "norm_paths = [os.path.join(test_norm_dir, f) for f in os.listdir(test_norm_dir)]\n"
      ],
      "metadata": {
        "id": "fszMfDvgUOIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Computing Baseline vs R-Marked Predictions"
      ],
      "metadata": {
        "id": "ufx57gh5UaLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_probs = []\n",
        "R_probs = []\n",
        "\n",
        "for p in tqdm(norm_paths, desc=\"NORMALs with and without R\"):\n",
        "    g = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
        "    g = cv2.resize(g, (224, 224))\n",
        "\n",
        "    pil_base = Image.fromarray(g).convert(\"L\")\n",
        "    x_base = test_tfms(pil_base).unsqueeze(0)\n",
        "    baseline_probs.append(get_prob(x_base))\n",
        "\n",
        "    g_R = add_R_marker(g)\n",
        "    pil_R = Image.fromarray(g_R).convert(\"L\")\n",
        "    x_R = test_tfms(pil_R).unsqueeze(0)\n",
        "    R_probs.append(get_prob(x_R))\n"
      ],
      "metadata": {
        "id": "NXe0EMl3UXrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting to Arrays + Printing Stats"
      ],
      "metadata": {
        "id": "bVaHqLkFUmBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_probs = np.array(baseline_probs)\n",
        "R_probs = np.array(R_probs)\n",
        "\n",
        "print(\"Baseline NORMAL mean prob:\", baseline_probs.mean())\n",
        "print(\"With fake R  mean prob  :\", R_probs.mean())\n",
        "print(\"Mean Δ prob (R - base)  :\", (R_probs - baseline_probs).mean())\n"
      ],
      "metadata": {
        "id": "pkQgC7c5Ue-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Significance Test"
      ],
      "metadata": {
        "id": "UzZsnoiCUjkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "t, p = ttest_rel(R_probs, baseline_probs)\n",
        "print(\"t =\", t, \"p =\", p)\n"
      ],
      "metadata": {
        "id": "qrfxo-olUhv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
